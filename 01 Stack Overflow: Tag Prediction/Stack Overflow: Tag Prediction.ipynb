{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Stack Overflow: Tag Prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fce83499a83d3f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1. Business Problem**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ef58dd331b82cdc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1.1 Description**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c91c6f9eb78b79fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Description\n",
    "\n",
    "Stack Overflow is the largest, most trusted online community for developers to learn, share their programming knowledge, and build their careers.\n",
    "\n",
    "Stack Overflow is something which every programmer use one way or another. Each month, over 50 million developers come to Stack Overflow to learn, share their knowledge, and build their careers. It features questions and answers on a wide range of topics in computer programming. The website serves as a platform for users to ask and answer questions, and, through membership and active participation, to vote questions and answers up or down and edit questions and answers in a fashion similar to a wiki or Digg. As of April 2014 Stack Overflow has over 4,000,000 registered users, and it exceeded 10,000,000 questions in late August 2015. Based on the type of tags assigned to questions, the top eight most discussed topics on the site are: Java, JavaScript, C#, PHP, Android, jQuery, Python and HTML."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "719ba4caa944e619"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem Statemtent**\n",
    "\n",
    "Suggest the tags based on the content that was there in the question posted on Stackoverflow."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e58012570fafa922"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Source: https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eddf35b046d165a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1.2 Source / useful links**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de7faef2890eae8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Source : https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction/data\n",
    "Youtube : https://youtu.be/nNDqbUhtIRg\n",
    "Research paper : https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tagging-1.pdf\n",
    "Research paper : https://dl.acm.org/citation.cfm?id=2660970&dl=ACM&coll=DL"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fc652de928be933"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1.3 Real World / Business Objectives and Constraints**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd4a0434602ceeda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Predict as many tags as possible with high precision and recall. --> If I missed a tag for a data point (Title+Description) my recall decreases. And if I provide incorrect tag to a data point my Precision decreases. \n",
    "2. Incorrect tags could impact customer experience on StackOverflow. \n",
    "3. No strict latency constraints."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d858a7cb23318b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Machine Learning problem**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4ea4edbc314e7d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.1 Data**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da5b614cd40cca80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.1.1 Data Overview"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de6233f50b07febe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "All of the data is in 2 files: Train and Test.\n",
    "\n",
    "Train.csv contains 4 columns: Id, Title, Body, Tags.\n",
    "\n",
    "--> Id - Unique identifier for each question\n",
    "--> Title - The question's title\n",
    "--> Body - The body of the question\n",
    "--> Tags - The tags associated with the question (all lowercase, should not contain tabs '\\t' or ampersands '&')\n",
    "\n",
    "Test.csv contains the same columns but without the Tags, which you are to predict.\n",
    "Size of Train.csv - 6.75GB\n",
    "Size of Test.csv - 2GB\n",
    "Number of rows in Train.csv = 6034195"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c65e667e765d964"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.1.2 Example Data point"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd67aa46f7083ed1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Title:  Implementing Boundary Value Analysis of Software Testing in a C++ program?\n",
    "Body:\n",
    "        #include&lt;\n",
    "        iostream&gt;\\n\n",
    "        #include&lt;\n",
    "        stdlib.h&gt;\\n\\n\n",
    "        using namespace std;\\n\\n\n",
    "        int main()\\n\n",
    "        {\\n\n",
    "                 int n,a[n],x,c,u[n],m[n],e[n][4];\\n         \n",
    "                 cout&lt;&lt;\"Enter the number of variables\";\\n         cin&gt;&gt;n;\\n\\n         \n",
    "                 cout&lt;&lt;\"Enter the Lower, and Upper Limits of the variables\";\\n         \n",
    "                 for(int y=1; y&lt;n+1; y++)\\n         \n",
    "                 {\\n                 \n",
    "                    cin&gt;&gt;m[y];\\n                 \n",
    "                    cin&gt;&gt;u[y];\\n         \n",
    "                 }\\n         \n",
    "                 for(x=1; x&lt;n+1; x++)\\n         \n",
    "                 {\\n                 \n",
    "                    a[x] = (m[x] + u[x])/2;\\n         \n",
    "                 }\\n         \n",
    "                 c=(n*4)-4;\\n         \n",
    "                 for(int a1=1; a1&lt;n+1; a1++)\\n         \n",
    "                 {\\n\\n             \n",
    "                    e[a1][0] = m[a1];\\n             \n",
    "                    e[a1][1] = m[a1]+1;\\n             \n",
    "                    e[a1][2] = u[a1]-1;\\n             \n",
    "                    e[a1][3] = u[a1];\\n         \n",
    "                 }\\n         \n",
    "                 for(int i=1; i&lt;n+1; i++)\\n         \n",
    "                 {\\n            \n",
    "                    for(int l=1; l&lt;=i; l++)\\n            \n",
    "                    {\\n                 \n",
    "                        if(l!=1)\\n                 \n",
    "                        {\\n                    \n",
    "                            cout&lt;&lt;a[l]&lt;&lt;\"\\\\t\";\\n                 \n",
    "                        }\\n            \n",
    "                    }\\n            \n",
    "                    for(int j=0; j&lt;4; j++)\\n            \n",
    "                    {\\n                \n",
    "                        cout&lt;&lt;e[i][j];\\n                \n",
    "                        for(int k=0; k&lt;n-(i+1); k++)\\n                \n",
    "                        {\\n                    \n",
    "                            cout&lt;&lt;a[k]&lt;&lt;\"\\\\t\";\\n               \n",
    "                        }\\n                \n",
    "                        cout&lt;&lt;\"\\\\n\";\\n            \n",
    "                    }\\n        \n",
    "                 }    \\n\\n        \n",
    "                 system(\"PAUSE\");\\n        \n",
    "                 return 0;    \\n\n",
    "        }\\n\n",
    "        </code></pre>\\n\\n\n",
    "        <p>The answer should come in the form of a table like</p>\\n\\n\n",
    "        <pre><code>       \n",
    "        1            50              50\\n       \n",
    "        2            50              50\\n       \n",
    "        99           50              50\\n       \n",
    "        100          50              50\\n       \n",
    "        50           1               50\\n       \n",
    "        50           2               50\\n       \n",
    "        50           99              50\\n       \n",
    "        50           100             50\\n       \n",
    "        50           50              1\\n       \n",
    "        50           50              2\\n       \n",
    "        50           50              99\\n       \n",
    "        50           50              100\\n\n",
    "        </code></pre>\\n\\n\n",
    "        <p>if the no of inputs is 3 and their ranges are\\n\n",
    "        1,100\\n\n",
    "        1,100\\n\n",
    "        1,100\\n\n",
    "        (could be varied too)</p>\\n\\n\n",
    "        <p>The output is not coming,can anyone correct the code or tell me what\\'s wrong?</p>\\n'\n",
    "Tags: 'c++ c'\n",
    "\n",
    "Points to be noted after seeing the data point:\n",
    "--> The tags are separated by the space \"c++ c\"\n",
    "--> The title is less verbose than body. \n",
    "--> The body can contain a lot of code."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f7444607a7259fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.2 Mapping the real-world problem to a Machine Learning Problem**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ad3bf225c4b3c26"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.2.1 Type of Machine Learning Problem**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7bb40fe22aa5550"
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is a **multi-label classification** problem. Multi-label Classification: Multilabel classification assigns to each sample a set of target labels. This can be thought as predicting properties of a data-point that are not mutually exclusive, such as topics that are relevant for a document. A question on Stackoverflow might be about any of C, Pointers, FileIO and/or memory-management at the same time or none of these.\n",
    "__Credit__: http://scikit-learn.org/stable/modules/multiclass.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cef2c6894d4a8a30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.2.2 Performance metric**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f85d53e3d6007971"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before going into the details we must know the metric system we are going to use to check the performance of our model. \n",
    "+ We can't use the conventional f1 score. Because it is for binary-class classification and not for multi-class and multi-label classification problem.  \n",
    "+ What we can do is to use one vs rest approach to calculate the f1 score for each individual classes. \n",
    "\n",
    "**Micro-Averaged F1-Score (Mean F Score)** : The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "In the multi-class and multi-label case, this is the weighted average of the F1 score of each class.\n",
    "\n",
    "**'Micro f1 score':**\n",
    "Calculate metrics globally by counting the total true positives, false negatives and false positives. This is a better metric when we have class imbalance.  --> It consider the number of occurrence of the classes in the data (weighted f1). \n",
    "\n",
    "**'Macro f1 score':**\n",
    "Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "https://www.kaggle.com/wiki/MeanFScore\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "\n",
    "**Hamming loss** : The Hamming loss is the fraction of labels that are incorrectly predicted.\n",
    "https://www.kaggle.com/wiki/HammingLoss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3518a33b44e6e2f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![f1 score](images/image1.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4cecff5a99a6a0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hamming loss : The Hamming loss is the fraction of labels that are incorrectly predicted.\n",
    "https://www.kaggle.com/wiki/HammingLoss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eda106d4188c3705"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Hamming Loss](images/image2.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a225b6b833209cf1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3. Exploratory Data Analysis**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "476a6fa5c7ce6cf4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3.1 Data Loading and Cleaning**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb4c6fedf1e8a9a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.1.1 Using Pandas with SQLite to Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3710669f0e36bbf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T15:52:12.198600Z",
     "start_time": "2024-08-21T15:52:12.185042Z"
    }
   },
   "id": "f4ca0efa49d4090f",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not os.path.isfile('data/dataset/train.db'):\n",
    "    start = datetime.now()\n",
    "    disl_engine = create_engine('sqlite:///data/dataset/train.db')\n",
    "    start = datetime.now()\n",
    "    chunksize = 180000\n",
    "    j = 0\n",
    "    index_start = 1\n",
    "    for df in pd.read_csv('data/dataset/Train.csv', names=['Id', 'Title', 'Body', 'Tags'], chunksize=chunksize, iterator=True, encoding='utf-8'):\n",
    "        df.index += index_start\n",
    "        j += 1\n",
    "        print(f'{j*chunksize} rows processed')\n",
    "        df.to_sql('data', disl_engine, if_exists='append')\n",
    "        index_start = df.index[-1] + 1\n",
    "    print(f'Time taken to run this cell: {datetime.now() - start}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T15:06:49.411962Z",
     "start_time": "2024-08-21T15:06:48.394803Z"
    }
   },
   "id": "2950c45a6825063e",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.1.2 Counting the number of rows"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e22be84891262757"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the database: 6034196\n",
      "Time taken to run this cell: 0:00:03.220105\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('data/dataset/train.db'):\n",
    "    start = datetime.now()\n",
    "    con = sqlite3.connect('data/dataset/train.db')\n",
    "    num_rows = pd.read_sql_query(\"SELECT count(*) FROM data\", con)\n",
    "    #Always remember to close the database\n",
    "    print(f'Number of rows in the database: {num_rows[\"count(*)\"].values[0]}')\n",
    "    con.close()\n",
    "    print(f'Time taken to run this cell: {datetime.now() - start}')\n",
    "else:\n",
    "    print(f'Please download the data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T15:06:52.635727Z",
     "start_time": "2024-08-21T15:06:49.412988Z"
    }
   },
   "id": "205353d67bbf92a8",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.1.3 Checking for duplicates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "baadc35531aff8a2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell: 0:05:36.315928\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('data/dataset/train.db'):\n",
    "    start = datetime.now()\n",
    "    con = sqlite3.connect('data/dataset/train.db')\n",
    "    df_no_dup = pd.read_sql_query(\"SELECT Title, Body, Tags, COUNT(*) as cnt_dup FROM data GROUP BY Title, Body, Tags\", con)\n",
    "    con.close()\n",
    "    print(f'Time taken to run this cell: {datetime.now() - start}')\n",
    "else:\n",
    "    print(f'Please download the data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T15:12:29.011649Z",
     "start_time": "2024-08-21T15:06:52.636585Z"
    }
   },
   "id": "78c8f0b77375fbee",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Title  \\\n0       Implementing Boundary Value Analysis of S...   \n1           Dynamic Datagrid Binding in Silverlight?   \n2           Dynamic Datagrid Binding in Silverlight?   \n3      java.lang.NoClassDefFoundError: javax/serv...   \n4      java.sql.SQLException:[Microsoft][ODBC Dri...   \n\n                                                Body  \\\n0  <pre><code>#include&lt;iostream&gt;\\n#include&...   \n1  <p>I should do binding for datagrid dynamicall...   \n2  <p>I should do binding for datagrid dynamicall...   \n3  <p>I followed the guide in <a href=\"http://sta...   \n4  <p>I use the following code</p>\\n\\n<pre><code>...   \n\n                                  Tags  cnt_dup  \n0                                c++ c        1  \n1          c# silverlight data-binding        1  \n2  c# silverlight data-binding columns        1  \n3                             jsp jstl        1  \n4                            java jdbc        2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Tags</th>\n      <th>cnt_dup</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Implementing Boundary Value Analysis of S...</td>\n      <td>&lt;pre&gt;&lt;code&gt;#include&amp;lt;iostream&amp;gt;\\n#include&amp;...</td>\n      <td>c++ c</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dynamic Datagrid Binding in Silverlight?</td>\n      <td>&lt;p&gt;I should do binding for datagrid dynamicall...</td>\n      <td>c# silverlight data-binding</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dynamic Datagrid Binding in Silverlight?</td>\n      <td>&lt;p&gt;I should do binding for datagrid dynamicall...</td>\n      <td>c# silverlight data-binding columns</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>java.lang.NoClassDefFoundError: javax/serv...</td>\n      <td>&lt;p&gt;I followed the guide in &lt;a href=\"http://sta...</td>\n      <td>jsp jstl</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>java.sql.SQLException:[Microsoft][ODBC Dri...</td>\n      <td>&lt;p&gt;I use the following code&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;...</td>\n      <td>java jdbc</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dup.head()\n",
    "# The duplicates are present in the data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T15:12:29.234418Z",
     "start_time": "2024-08-21T15:12:29.026843Z"
    }
   },
   "id": "961ebcd001170d6c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 1827881 and the percentage: 30.292038906260256%\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of duplicate rows: {num_rows[\"count(*)\"].values[0] - df_no_dup.shape[0]} and the percentage: {(1 - df_no_dup.shape[0]/num_rows[\"count(*)\"].values[0])*100}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T15:12:29.247714Z",
     "start_time": "2024-08-21T15:12:29.239920Z"
    }
   },
   "id": "c9be225d61ef0058",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we want to know how many times a question repeated in the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4761ecbb953b00e2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "cnt_dup\n1    2656284\n2    1272336\n3     277575\n4         90\n5         25\n6          5\nName: count, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dup.cnt_dup.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T15:12:29.337110Z",
     "start_time": "2024-08-21T15:12:29.249551Z"
    }
   },
   "id": "44bd8f1e6f2e0ec",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, here we can see number of questions repeated one time are 2656284 and number of questions repeated 2 times are 1272336 and so on. \n",
    "Now, let's add one more feature which tells number of tags per question in the dataset. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8209daeb6d4185fa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 6\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(df_no_dup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTags\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m777547\u001B[39m])\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#for tag in tqdm(df_no_dup[\"Tags\"]):\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#    df_no_dup[\"tag_count\"] = len(tag.split(\" \"))\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#df_no_dup.head()\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m df_no_dup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtag_count\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf_no_dup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTags\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#print(f'Time taken to run this cell: {datetime.now() - start}')\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m#df_no_dup.head()\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ML/.venv/lib/python3.9/site-packages/pandas/core/series.py:4897\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[1;32m   4769\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4770\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4771\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4776\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4777\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4778\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4779\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4780\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4895\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4896\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4897\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4898\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4899\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4900\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4901\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4902\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4903\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4904\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ML/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[0;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ML/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[1;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[1;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[1;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[1;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/PycharmProjects/ML/.venv/lib/python3.9/site-packages/pandas/core/base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[0;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[1;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[0;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ML/.venv/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[0;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[1;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[1;32m   1747\u001B[0m     )\n",
      "File \u001B[0;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn[25], line 6\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(df_no_dup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTags\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m777547\u001B[39m])\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#for tag in tqdm(df_no_dup[\"Tags\"]):\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#    df_no_dup[\"tag_count\"] = len(tag.split(\" \"))\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#df_no_dup.head()\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m df_no_dup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtag_count\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df_no_dup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTags\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m text: \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#print(f'Time taken to run this cell: {datetime.now() - start}')\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m#df_no_dup.head()\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(df_no_dup[\"Tags\"][777547])\n",
    "#for tag in tqdm(df_no_dup[\"Tags\"]):\n",
    "#    df_no_dup[\"tag_count\"] = len(tag.split(\" \"))\n",
    "#df_no_dup.head()\n",
    "df_no_dup[\"tag_count\"] = df_no_dup[\"Tags\"].apply(lambda text: len(text.split(\" \") if text and text != int else 0))\n",
    "#print(f'Time taken to run this cell: {datetime.now() - start}')\n",
    "#df_no_dup.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-21T16:57:06.276176Z",
     "start_time": "2024-08-21T16:57:05.934010Z"
    }
   },
   "id": "dfd9d3e05c7bdccd",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "Distribution of number of tags per question."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e24a814ef10b2637"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_no_dup[\"tag_count\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "531a60a62b3a66d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a new database with no duplicates and add one more feature tag_count. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4e1d4635160850"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if os.path.isfile(\"data/dataset/train_no_dub.db\"):\n",
    "    start = datetime.now()\n",
    "    disk_dup = create_engine(\"sqlite:///data/dataset/train.db\")\n",
    "    no_dup = pd.DataFrame(df_no_dup, columns=['Title', 'Body', 'Tags'])\n",
    "    no_dup.to_sql('no_dup', disk_dup)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4caa6813edb36b39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#creating the connection with database file.\n",
    "if os.path.isfile('train_no_dup.db'):\n",
    "    start = datetime.now()\n",
    "    con = sqlite3.connect('train_no_dup.db')\n",
    "    tag_data = pd.read_sql_query(\"\"\"SELECT Tags FROM no_dup_train\"\"\", con)\n",
    "    #Always remember to close the database\n",
    "    con.close()\n",
    "\n",
    "    # Let's now drop unwanted column.\n",
    "    tag_data.drop(tag_data.index[0], inplace=True)\n",
    "    #Printing first 5 columns from our data frame\n",
    "    tag_data.head()\n",
    "    print(\"Time taken to run this cell :\", datetime.now() - start)\n",
    "else:\n",
    "    print('Download the data')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f73f601c72361910",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
