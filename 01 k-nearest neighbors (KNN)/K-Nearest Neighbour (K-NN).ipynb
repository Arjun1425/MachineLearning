{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Load data.\n",
    "\n",
    "Here, I have imdb Preprocessed data.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3741fab36b5cbaf5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class                                         clean_text\n",
      "0      0  slow moving aimless movie distressed drifting ...\n",
      "1      0  not sure lost flat characters audience nearly ...\n",
      "2      0  attempting artiness black white clever camera ...\n",
      "3      0                        little music anything speak\n",
      "4      1  best scene movie gerardo trying find song keep...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../../Downloads/Data for ML/imdb.txt\")\n",
    "print(data.head())"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-14T13:53:40.550868Z",
     "start_time": "2024-06-14T13:53:40.542751Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the text data into Vector format. \n",
    "\n",
    "--> Using Bag of words.\n",
    "--> Always split data first before preprocessing. But here we already got preprocessed data so don't worry about that.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50518f1820defd85"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points: 746\n",
      "Number of data points in training set: 476\n",
      "Length of cross-validation set: 120\n",
      "Number of data points in test set: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data['clean_text'].values\n",
    "Y = data['class'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'Total number of data points: {len(X)}')\n",
    "print(f\"Number of data points in training set: {len(x_train)}\")\n",
    "print(f\"Length of cross-validation set: {len(x_cv)}\")\n",
    "print(f\"Number of data points in test set: {len(x_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T14:32:56.073382Z",
     "start_time": "2024-06-14T14:32:56.064643Z"
    }
   },
   "id": "f74746324f9756c8",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fit your model on training data only. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4869454dfcea6d3a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should not do like that.\n",
      "x_train.shape = (476, 2145), x_cv.shape = (120, 752), x_test.shape = (150, 929)\n",
      "NOTE: THE NUMBER OF COLUMNS IN EACH OF THE VECTOR WONT BE SAME --> Which explains the problem.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "print(\"You should not do like that.\") \n",
    "x_train = cv.fit_transform(x_train)      # --> Here I want to fit cv only with the train data. \n",
    "x_cv = cv.fit_transform(x_cv)\n",
    "x_test = cv.fit_transform(x_test)        # --> By doing that you are causing data leakage problem. \n",
    "print(f'{x_train.shape = }, {x_cv.shape = }, {x_test.shape = }')\n",
    "print(\"NOTE: THE NUMBER OF COLUMNS IN EACH OF THE VECTOR WONT BE SAME --> Which explains the problem.\")\n",
    "print('='*100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T14:32:51.727671Z",
     "start_time": "2024-06-14T14:32:51.702962Z"
    }
   },
   "id": "ec03a534e7eb4ea2",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should do like that.\n",
      "x_train.shape = (476, 2145), x_cv.shape = (120, 2145), x_test.shape = (150, 2145)\n"
     ]
    }
   ],
   "source": [
    "print(\"You should do like that.\")\n",
    "cv = CountVectorizer()\n",
    "cv.fit(x_train) # fit has to happen only on train data\n",
    "\n",
    "x_train = cv.transform(x_train)\n",
    "x_cv = cv.transform(x_cv)\n",
    "x_test = cv.transform(x_test)\n",
    "print(f'{x_train.shape = }, {x_cv.shape = }, {x_test.shape = }')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T14:33:00.112113Z",
     "start_time": "2024-06-14T14:33:00.089645Z"
    }
   },
   "id": "e140ae940731b7fc",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    " YOU SHOULD NOT DO LIKE THIS \n",
    "\n",
    "1.  THE VOCABULARY SHOULD BUILT ONLY WITH THE WORDS OF TRAIN DATA\n",
    "    vectorizer = CountVectorizer()\n",
    "    x_train_bow = vectorizer.fit_transform(X_train)\n",
    "    x_cv_bow = vectorizer.fit_transform(X_cv)\n",
    "    x_test_bow = vectorizer.fit_transform(X_test)\n",
    "\n",
    "2.  DATA LEAKAGE PROBLEM: IF WE DO LIKE THIS WE ARE LOOKING AT THE TEST DATA BEFORE MODELING\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_bow = vectorizer.fit_transfomr(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_bow, Y, test_size=0.33)\n",
    "\n",
    "3. YOU SHOULD PASS THE PROBABILITY SCORES NOT THE PREDICTED VALUES\n",
    "    y_pred =  neigh.predict(X)\n",
    "    roc_auc_score(y_ture,y_pred)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93f0dd0bdaeaa7b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "When you do: \n",
    "--> vec =  CountVectorizer()\n",
    "Means it will initiate the CountVectorizer with default parameters.\n",
    "\n",
    "--> vec.fit(Train_text): Means that internally it is only learning the vocabulary of `Text` i.e. unique n-grams\n",
    "\n",
    "--> bag_of_words = vec.transform(Train_text) \n",
    "Means it is applying that learned parameters (vocabulary) to the data and thus giving you output i.e. words in Bag of words format. \n",
    "Now, as you should know that the vocabulary (unique n-grams) can be different for Train Text and Test Text thus they will give you different dimensional matrices for Train and Test. \n",
    "\n",
    "So what you should do is -  vec = CountVectorizer(), vec.fit(Train_text)\n",
    "which learns the vocabulary of Train Text and then apply or transform your both Train Text and Test Text  using that  \n",
    "learned vocabulary to ensure the same dimensions for both of them by doing -\n",
    "\n",
    "bag_of_words_train = vec.transform(Train_text) and\n",
    "bag_of_words_test = vec.transform(Test_text)\n",
    "\n",
    "so to conclude\n",
    "model =  CountVectorizer()\n",
    "model.fit(train_text)\n",
    "train_bow = model.transform(train_text)\n",
    "test_bow = model.transform(test_text) \n",
    "or \n",
    "model =  CountVectorizer()\n",
    "train_bow = model.fit_transform(train_text)\n",
    "test_bow = model.transform(test_text) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a8b37f8e375e7ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8c407eb54e0bb6f3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
